---
title: "Report"
author: "Guangkun Bao"
date: "2020/11/14"
output: html_document
---

```{r setup, include=FALSE}
Sys.setenv(LANG = "en")
knitr::opts_chunk$set(echo = TRUE)
```

# 7.5.1

## a
Since we have:

$$f(x) = \frac{1}{5\sqrt{2\pi}}x^{2}e^{-\frac{(x-2)^{2}}{2}}$$
and,

$$g(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}$$
Then we set 

$$w(x) = \frac{f(x)}{g(x)} = 0.2x^{2}e^{2x-2}$$

So we have:

```{r}
for (n in c(1000,10000,50000)){
        x = rnorm(n)
        mean = mean(0.2 * x^4 * exp(2*x - 2))
        var =  var(0.2 * x^4 * exp(2*x - 2))
        print(paste('n :',n))
        print(paste('mean :', mean, 'variance :', var))
}
```

## b


Since 

$$h(x)f(x) = \frac{1}{5\sqrt{2\pi}}x^{4}e^{-\frac{(x-2)^{2}}{2}},h(x) = x^{2}$$

We want to find a g(x) that is proportional to h(x)f(x). We only need to care about $x^{4}$, since $e^{-\frac{(x-2)^{2}}{2}}$ is relatively small.

Here we choose the pdf of Gamma(5,1) as g(x), where

$$g(x) = \frac{1}{24}x^{4}e^{-x}.$$
Thus we have,

$$h(x)w(x) = \frac{24}{5\sqrt{2\pi}}e^{-\frac{x^{2}-2x+4}{2}}$$

## c

```{r}
for (n in c(1000,10000,50000)){
        x = rgamma(n, 5, 1)
        hw = 24*exp(-(x^2 - 6*x + 4)/2)/(5*(2*pi)^0.5)
        mean = mean(hw)
        var =  var(hw)
        print(paste('n :',n))
        print(paste('mean :',mean,'variance :',var))
        }
```

## d

From the output of the two methods, it's obviously the second one has a much smaller variances. So the second method is preferred.

# 7.5.2

## a

Since,

$$S(T) = S(0)e^{r - \frac{1}{2}\sigma^{2}T + \sigma W(T)}$$

$$W(t) = \sqrt{T}Z, Z \sim N(0,1)$$

So we have the algorithm :

```{r}
s0 = 1
r = 0.05
n = 12
seed = 1
ST = function(n,t,sigma){
        set.seed(seed)
        z = rnorm(n)
        wt = (t^0.5)*z
        st = s0*exp((r-0.5*sigma^2)*t+sigma*wt)
        return(st)
        }
```

Now, implement the algorithm to simulate 10 paths of S(1) with $\sigma = 1$.

```{r}
ST(10,1,1)
```

## b
First we define five functions for $P_{A}, P_{E}, P_{G}, S_{A}, S_{G}.$

```{r}
m = 12

maxzero = function(x) {return(max(x,0))}

SA = function(n,t,sigma){
        f = c()
        for (i in 1:m){
                f = cbind(f,ST(n,i*t/m,sigma))
                }
        return(apply(f, 1, mean))
        }

SG = function(n,t,sigma){
        f = c()
        for (i in 1:m){
                f = cbind(f,ST(n,i*t/m,sigma))
                }
        return(apply(f, 1, prod)^(1/m))
        }

PA = function(n,t,sigma,k){
        f = exp(-r*t)*apply(matrix(SA(n,t,sigma)-k), 1, maxzero)
        return(f)
        }

PE = function(n,t,sigma,k){
        f = exp(-r*t)*apply(matrix(ST(n,t,sigma)-k), 1, maxzero)
        return(f)
        }

PG = function(n,t,sigma,k){
        f = exp(-r*t)*apply(matrix(SG(n,t,sigma)-k), 1, maxzero)
        return(f)
        }
```

```{r}
sigma = 0.5
t = 1
n = 5000
for(k in c(1.1,1.2,1.3,1.4,1.5)){
        st = ST(n,t,sigma)
        sa = SA(n,t,sigma)
        sg = SG(n,t,sigma)
        pa = PA(n,t,sigma,k)
        pe = PE(n,t,sigma,k)
        pg = PG(n,t,sigma,k)
        cor1 = cor(pa,st)
        cor2 = cor(pa,pe)
        cor3 = cor(pa,pg)
        print(paste('K :',k))
        print(paste('correlations :',cor1,cor2,cor3))
        }
```
From the above output, we can find when k increases the correlation coefficient between $P_{A}$ and $S(T)$ decreases obviously, the correlation coefficient between $P_{A}$ and $P_{E}$ decreases slightly, the correlation coefficient between $P_{A}$ and $P_{G}$ is stable.

## c

```{r}
t = 1
k = 1.5
n = 5000
for(sigma in c(0.2,0.3,0.4,0.5)){
        st = ST(n,t,sigma)
        sa = SA(n,t,sigma)
        sg = SG(n,t,sigma)
        pa = PA(n,t,sigma,k)
        pe = PE(n,t,sigma,k)
        pg = PG(n,t,sigma,k)
        cor1 = cor(pa,st)
        cor2 = cor(pa,pe)
        cor3 = cor(pa,pg)
        print(paste('sigma :',sigma))
        print(paste('correlations :',cor1,cor2,cor3))
        }
```
From the above output, we find that when $\sigma$ increases, the correlation coefficient between $P_{A}$ and $S(T)$ increases obviously, the correlation coefficient between $P_{A}$ and $P_{E}$ increases slightly, the correlation coefficient between $P_{A}$ and $P_{G}$ is stable.

## d

```{r}
sigma = 0.5
k = 1.5
n = 5000
for(t in c(0.4,0.7,1,1.3,1.6)){
        st = ST(n,t,sigma)
        sa = SA(n,t,sigma)
        sg = SG(n,t,sigma)
        pa = PA(n,t,sigma,k)
        pe = PE(n,t,sigma,k)
        pg = PG(n,t,sigma,k)
        cor1 = cor(pa,st)
        cor2 = cor(pa,pe)
        cor3 = cor(pa,pg)
        print(paste('when T is',t))
        print(paste('correlations :',cor1,cor2,cor3))
        }
```
From the above output, We find that when T increases, the correlation coefficient between $P_{A}$ and $S(T)$ increases obviously, the correlation coefficient between $P_{A}$ and $P_{E}$ increases slightly, the correlation coefficient between $P_{A}$ and $P_{G}$ is stable.

## e

```{r}
sigma = 0.4
t = 1
k = 1.5
n = 500
r = 0.05
s0 = 1
m = 12
Lnorm_E = function(s0,k,mu,sigma){
        lg = (log(s0/k)+mu+sigma^2)/sigma
        f  = s0*exp(mu+0.5*sigma^2)*pnorm(lg)-k*pnorm(lg-sigma)
        return(f)
        }
```


```{r}
cv = function(n,r,sigma,s0,k,t){
        pa = PA(n,t,sigma,k)
        pg = PG(n,t,sigma,k)
        tbar = (m+1)/(2*m)
        sbar2 = sigma^2 / m^2 / tbar * sum((2*seq(m)-1)* ((m+1)*t/m - t/m*seq(m)))    
        pg_true_mean = Lnorm_E(s0,k,(r-0.5*sigma^2)*tbar,sqrt(sbar2*tbar))
        pa_cv_mean = mean(pa) - cov(pg,pa) / var(pg) * (mean(pg)-pg_true_mean)
        return(pa_cv_mean) 
        }

no_cv = function(n,r,sigma,s0,k,t){
        pa = PA(n,t,sigma,k)
        pa_mean = mean(pa)
        return(pa_mean)
        }
```

Here, we run two functions(control vs no control) 500 times and compare their estimate SD.

```{r}
estimator1 = c()
estimator2 = c()

for (i in 1:500){
        seed = i
        res1 = cv(n,r,sigma,s0,k,t)
        res2 = no_cv(n,r,sigma,s0,k,t)
        estimator1 = c(estimator1,res1)
        estimator2 = c(estimator2,res2)
}

sd(estimator1)
sd(estimator2)
```

From the results we can see, using a control variate, we will have a lower SD.
